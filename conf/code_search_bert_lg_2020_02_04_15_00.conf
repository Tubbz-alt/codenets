include "./default.conf"

tokenizers {
    build_path = "./build_tokenizers/with_lang"
}

dataset {
    common_params {
        parallelize = false
        do_lowercase = true
        special_tokens = ["<unk>", "<lg>"]
    }
}

training {
    name = "code_search_bert"
    iteration = "2020_02_04_21_00"

}